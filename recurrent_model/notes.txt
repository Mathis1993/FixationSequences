Last Layer LogSoftmax and then just NLLLoss?
--> Nein, einfach direkt CrossEntropyLoss

Bilder auf 10x10 runterskalieren, bzw. Vorhersage nur in 10x10 Grid (Vorherzusagen, welche grid cell von 100 insgesamt wann fixiert wird, wäre ja auch schon was)? (Vor allem, weil nicht genug memory für LSTM)

Oder: Bilder so groß wie mgl. durch VGG, dann am Ende auf 10x10 runter, sodass wir 10x10 Saliency Map (bzw. density) erhalten. Das dann zusammen mit einer fixation location pro time step in LSTM --> Outputs aus VGG zwischenspeichern?!

Oder: Baselinemodel nehmen (VGG und Readout Network) und darauf LSTM/GRU setzen?
--> Baselinemodel vortrainiert laden und Parameter freezen, vllt. dann genügend memory?

DeepgazeII-Saliency-Map and then RNN?

----------------------------------

nicht one-hot encoded, sondern direkt x- und y-Koordinate vorhersagen
kein teacher forcing

- vllt iwie batches hinbekommen, damit Lernkurve glatter wird?
- Durchlauf durch das CNN in das Erstellen des Datasets schieben? Oder eine Netzwerkklasse mit CNN und RNN? Aber würde dann das zusammenschustern des RNN-Inputs aus dem CNN-Output den backward-call stören?

- LSTM und GRU-Version - done
- Unnötige Version(en) löschen - done
- Training Loop vllt dann eine Datei für alle Modellarten mgl.? - done
- Wenn alles angepasst, pushen