{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood_Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes:\n",
    "    - activation_batch of size (batch_size, 1, x, y) describing the predicted probability distribution for fixations \n",
    "      (how likely is each image to be fixated) over all pixels of an (x,y)-image \n",
    "    - target_batch of size (batch_size, 1, x, y) describing the amount of fixations every pixel got (0 for no fixation, 1 for\n",
    "      one fixation, 2 for two fixations and so on)\n",
    "      \n",
    "    Gives:\n",
    "    - negative log-likelihood_loss: likelihood of fixation locations in the target assuming the predicted probability\n",
    "      distribution. If on pixel has more than one fixation, its likelihood is counted as many times. For the implementation\n",
    "      this means that we can just multipy the predicted probability distribution with the target map. In doing so, we evaluate\n",
    "      the predicted probability density in the fixated locations, counting a location more than once if it was fixated more \n",
    "      than once\n",
    "    - mean of negative log-likelihood_loss over the given batch is returned\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Likelihood_Loss, self).__init__()\n",
    "        \n",
    "    def forward(self, activation_batch, target_batch):\n",
    "        x = torch.log(activation_batch * target_batch)\n",
    "        x = torch.sum(torch.sum(x, dim=-1), dim=-1)\n",
    "        return -1*torch.mean(x) #mean over the batch\n",
    "\n",
    "    \n",
    "criterion = Likelihood_Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood_Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes:\n",
    "    - activation_batch of size (batch_size, 1, x, y) describing the predicted probability distribution for fixations \n",
    "      (how likely is each image to be fixated) over all pixels of an (x,y)-image \n",
    "    - target_batch of size (batch_size, 1, x, y) describing the amount of fixations every pixel got (0 for no fixation, 1 for\n",
    "      one fixation, 2 for two fixations and so on)\n",
    "      \n",
    "    Gives:\n",
    "    - negative log-likelihood_loss: log-likelihood of fixation locations in the target assuming the predicted probability\n",
    "      distribution. If on pixel has more than one fixation, its likelihood is counted as many times. For the implementation\n",
    "      this means that we can just multipy the predicted probability distribution with the target map. In doing so, we evaluate\n",
    "      the predicted probability density in the fixated locations, counting a location more than once if it was fixated more \n",
    "      than once\n",
    "    - mean of negative log-likelihood_loss over the given batch is returned\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Likelihood_Loss, self).__init__()\n",
    "        \n",
    "    def forward(self, activation_batch, target_batch):\n",
    "        #print(activation_batch[0])\n",
    "        #print(torch.sum(activation_batch[0]))\n",
    "        #Wieso log-Likelihood? --> Kümmerer et al.\n",
    "        #Wie ohne Offset stabil machen?\n",
    "        #x = activation_batch * target_batch\n",
    "        #x = x[x.nonzero().detach_()]\n",
    "        #x = -torch.log(activation_batch * target_batch + 1e-05)\n",
    "        #x = -(activation_batch * target_batch)\n",
    "        #print(torch.sum(x))\n",
    "        #x = torch.sum(torch.sum(x, dim=-1), dim=-1)\n",
    "        #print(torch.mean(x))\n",
    "        #return torch.mean(x) #mean over the batch\n",
    "        \n",
    "        #x = torch.log(activation_batch + 1e-10) + torch.log(target_batch + 1e-10)\n",
    "        #x = torch.sum(torch.sum(x, dim=-1), dim=-1)\n",
    "        #print(torch.mean(x))\n",
    "        #return torch.mean(x)\n",
    "        \n",
    "        loss = 0\n",
    "        for h in range(activation_batch.size(0)):\n",
    "            for (i,j) in target_batch[h]:\n",
    "                if (i,j) == (-1000,-1000):\n",
    "                    break\n",
    "                loss += torch.log(activation_batch[h,0,i,j] + 1e-10)\n",
    "        loss /= activation_batch.size(0)\n",
    "        #print(loss)\n",
    "        return loss * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = Likelihood_Loss()\n",
    "criterion(torch.randn(8,1,5,5), torch.randn(8,5,2).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4548, 0.1118, 0.0370, 0.8761],\n",
       "          [0.4780, 0.1519, 0.1048, 0.1138],\n",
       "          [0.5016, 0.3614, 0.6444, 0.2943],\n",
       "          [0.3240, 0.2400, 0.1644, 0.6921]],\n",
       "\n",
       "         [[0.2292, 0.3721, 0.8452, 0.0470],\n",
       "          [0.4249, 0.2761, 0.5593, 0.4710],\n",
       "          [0.3816, 0.2314, 0.2987, 0.5263],\n",
       "          [0.4711, 0.5550, 0.6006, 0.2744]],\n",
       "\n",
       "         [[0.3160, 0.5161, 0.1178, 0.0769],\n",
       "          [0.0971, 0.5720, 0.3359, 0.4152],\n",
       "          [0.1168, 0.4072, 0.0569, 0.1793],\n",
       "          [0.2049, 0.2050, 0.2349, 0.0335]]],\n",
       "\n",
       "\n",
       "        [[[0.4739, 0.5480, 0.1776, 0.1216],\n",
       "          [0.4542, 0.2430, 0.1301, 0.3771],\n",
       "          [0.4173, 0.2845, 0.4166, 0.3313],\n",
       "          [0.0319, 0.3617, 0.1070, 0.3660]],\n",
       "\n",
       "         [[0.0664, 0.2292, 0.4134, 0.6667],\n",
       "          [0.3911, 0.2133, 0.8382, 0.2395],\n",
       "          [0.2644, 0.5553, 0.5252, 0.2442],\n",
       "          [0.1197, 0.5685, 0.2306, 0.5204]],\n",
       "\n",
       "         [[0.4597, 0.2228, 0.4090, 0.2117],\n",
       "          [0.1546, 0.5437, 0.0318, 0.3834],\n",
       "          [0.3183, 0.1602, 0.0582, 0.4244],\n",
       "          [0.8484, 0.0698, 0.6624, 0.1136]]],\n",
       "\n",
       "\n",
       "        [[[0.8527, 0.5142, 0.2589, 0.2289],\n",
       "          [0.0283, 0.0912, 0.3352, 0.5831],\n",
       "          [0.1453, 0.3272, 0.1731, 0.1139],\n",
       "          [0.0796, 0.3512, 0.2432, 0.1856]],\n",
       "\n",
       "         [[0.0884, 0.4591, 0.4298, 0.1363],\n",
       "          [0.4610, 0.3223, 0.5162, 0.2188],\n",
       "          [0.5929, 0.4918, 0.3235, 0.1028],\n",
       "          [0.8472, 0.2761, 0.2065, 0.3686]],\n",
       "\n",
       "         [[0.0590, 0.0267, 0.3113, 0.6348],\n",
       "          [0.5106, 0.5865, 0.1486, 0.1982],\n",
       "          [0.2619, 0.1809, 0.5034, 0.7833],\n",
       "          [0.0731, 0.3727, 0.5504, 0.4459]]],\n",
       "\n",
       "\n",
       "        [[[0.5692, 0.5103, 0.1197, 0.2750],\n",
       "          [0.1783, 0.6176, 0.5846, 0.3815],\n",
       "          [0.4240, 0.6593, 0.2368, 0.7255],\n",
       "          [0.2130, 0.6880, 0.0318, 0.0308]],\n",
       "\n",
       "         [[0.3653, 0.2607, 0.8549, 0.3078],\n",
       "          [0.1989, 0.0786, 0.0631, 0.1541],\n",
       "          [0.1279, 0.1659, 0.6706, 0.0852],\n",
       "          [0.1307, 0.1160, 0.4076, 0.8490]],\n",
       "\n",
       "         [[0.0656, 0.2290, 0.0254, 0.4172],\n",
       "          [0.6229, 0.3039, 0.3524, 0.4643],\n",
       "          [0.4481, 0.1748, 0.0926, 0.1892],\n",
       "          [0.6563, 0.1960, 0.5607, 0.1201]]],\n",
       "\n",
       "\n",
       "        [[[0.1851, 0.4344, 0.2742, 0.5816],\n",
       "          [0.3347, 0.7665, 0.3543, 0.4156],\n",
       "          [0.8996, 0.0547, 0.1044, 0.1953],\n",
       "          [0.1470, 0.5954, 0.0160, 0.6973]],\n",
       "\n",
       "         [[0.2547, 0.1565, 0.0798, 0.2920],\n",
       "          [0.2939, 0.1858, 0.2294, 0.4071],\n",
       "          [0.0362, 0.1918, 0.8627, 0.4188],\n",
       "          [0.1341, 0.1770, 0.5464, 0.0876]],\n",
       "\n",
       "         [[0.5602, 0.4091, 0.6461, 0.1264],\n",
       "          [0.3714, 0.0477, 0.4164, 0.1773],\n",
       "          [0.0642, 0.7535, 0.0329, 0.3859],\n",
       "          [0.7189, 0.2276, 0.4375, 0.2151]]],\n",
       "\n",
       "\n",
       "        [[[0.1193, 0.4829, 0.0801, 0.2208],\n",
       "          [0.1492, 0.5268, 0.4495, 0.2112],\n",
       "          [0.2871, 0.4696, 0.3819, 0.2616],\n",
       "          [0.7078, 0.1951, 0.2216, 0.2253]],\n",
       "\n",
       "         [[0.4696, 0.3334, 0.2399, 0.4053],\n",
       "          [0.6927, 0.3485, 0.3863, 0.6706],\n",
       "          [0.6497, 0.2395, 0.3352, 0.1443],\n",
       "          [0.1730, 0.6297, 0.5154, 0.6067]],\n",
       "\n",
       "         [[0.4110, 0.1837, 0.6800, 0.3739],\n",
       "          [0.1581, 0.1247, 0.1642, 0.1182],\n",
       "          [0.0632, 0.2910, 0.2829, 0.5941],\n",
       "          [0.1193, 0.1752, 0.2630, 0.1680]]],\n",
       "\n",
       "\n",
       "        [[[0.4067, 0.0960, 0.3844, 0.0824],\n",
       "          [0.0803, 0.0308, 0.4135, 0.5397],\n",
       "          [0.3774, 0.4403, 0.3038, 0.0918],\n",
       "          [0.7718, 0.0231, 0.0182, 0.1611]],\n",
       "\n",
       "         [[0.4593, 0.0497, 0.2811, 0.1547],\n",
       "          [0.3650, 0.8010, 0.3471, 0.1517],\n",
       "          [0.1253, 0.3844, 0.1262, 0.1447],\n",
       "          [0.1974, 0.1524, 0.0746, 0.0696]],\n",
       "\n",
       "         [[0.1341, 0.8543, 0.3345, 0.7630],\n",
       "          [0.5547, 0.1683, 0.2394, 0.3086],\n",
       "          [0.4972, 0.1753, 0.5700, 0.7635],\n",
       "          [0.0309, 0.8245, 0.9071, 0.7692]]],\n",
       "\n",
       "\n",
       "        [[[0.7482, 0.5579, 0.7417, 0.0524],\n",
       "          [0.3592, 0.4816, 0.7349, 0.0354],\n",
       "          [0.1402, 0.0621, 0.4847, 0.3145],\n",
       "          [0.3324, 0.2843, 0.1466, 0.0439]],\n",
       "\n",
       "         [[0.0875, 0.1697, 0.1204, 0.7483],\n",
       "          [0.4560, 0.2442, 0.2429, 0.5071],\n",
       "          [0.5277, 0.8531, 0.0674, 0.3379],\n",
       "          [0.3091, 0.4359, 0.5810, 0.0171]],\n",
       "\n",
       "         [[0.1643, 0.2724, 0.1379, 0.1993],\n",
       "          [0.1848, 0.2742, 0.0222, 0.4575],\n",
       "          [0.3321, 0.0848, 0.4479, 0.3476],\n",
       "          [0.3585, 0.2798, 0.2724, 0.9389]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(8,3,4,4)\n",
    "m = nn.Softmax2d()\n",
    "m(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 100, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(8,1,100,100)\n",
    "y = nn.Softmax(2)(x.view(*x.size()[:2], -1)).view_as(x)\n",
    "#*x.size()[:2] gibt (8,1), also (8,1,-1) als Dimensionen also (8,1,16). Dann Softmax über dim=2\n",
    "y[2,0].sum()\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1250, 0.0750, 0.5457, 0.2542],\n",
      "        [0.0623, 0.1755, 0.5490, 0.2131],\n",
      "        [0.0455, 0.5870, 0.2314, 0.1361],\n",
      "        [0.0398, 0.1136, 0.4456, 0.4009]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.0000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4,4)\n",
    "b = functional.softmax(a, dim=-1)\n",
    "print(b)\n",
    "torch.sum(functional.softmax(b, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(8,100,100)\n",
    "summe = torch.sum(torch.sum(target, -1), -1)\n",
    "print(target.size())\n",
    "target = target[0]/summe[0]\n",
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sum(target,-1), -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "inputs = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(inputs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([139864837979016,        67909120,              32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, dtype=torch.long)#.random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 0, 0, 1, 0, 1, 2, 0, 2, 2],\n",
      "         [0, 2, 0, 2, 0, 2, 0, 2, 1, 0],\n",
      "         [0, 0, 2, 2, 0, 1, 0, 0, 0, 1],\n",
      "         [2, 1, 0, 1, 1, 1, 1, 1, 2, 2],\n",
      "         [1, 2, 1, 2, 1, 2, 1, 1, 1, 1],\n",
      "         [1, 0, 0, 0, 1, 0, 2, 0, 0, 0],\n",
      "         [1, 1, 1, 2, 2, 1, 2, 0, 2, 2],\n",
      "         [1, 0, 1, 2, 1, 2, 0, 0, 0, 0],\n",
      "         [2, 2, 0, 0, 2, 1, 2, 2, 0, 1],\n",
      "         [2, 0, 0, 2, 2, 1, 1, 1, 2, 1]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "c, h, w = 1, 10, 10\n",
    "nb_classes = 3\n",
    "x = torch.randn(batch_size, c, h, w)\n",
    "target = torch.empty(batch_size, h, w, dtype=torch.long).random_(nb_classes)\n",
    "print(target)\n",
    "\n",
    "model = nn.Conv2d(c, nb_classes, 3, 1, 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "output = model(x)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
