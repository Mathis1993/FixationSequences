{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from utils.Dataset_And_Transforms import FigrimFillersDataset, Downsampling, ToTensor, SequenceModeling, ExpandTargets\n",
    "from utils.Create_Datasets import create_datasets   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_datasets(batch_size=5, data_transform=transforms.Compose([ToTensor(),Downsampling(10), SequenceModeling()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_l = []\n",
    "fixations_lengths = []\n",
    "for i, example in enumerate(train_loader): #start at index 0\n",
    "            # get the inputs\n",
    "            image = example[\"image\"]\n",
    "            fixations = example[\"fixations\"]\n",
    "            states = example[\"states\"]\n",
    "            length = example[\"fixations_length\"]\n",
    "\n",
    "            \n",
    "            if i == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixations.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the sequence lengths in descending order, keep track of the old indices, as the fixations' and token-indices'\n",
    "#batch-dimension needs to be rearranged in that way\n",
    "length_s, sort_idx = torch.sort(length, 0, descending=True)\n",
    "sort_idx\n",
    "#make length_s to list\n",
    "length_s = list(length_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange batch-dimensions (directly getting rid of the additional dimension this introduces)\n",
    "fixations = fixations[sort_idx].view(fixations.size(0), fixations.size(-2), fixations.size(-1))\n",
    "states = states[sort_idx].view(states.size(0), states.size(-1))\n",
    "#Da der Input immer derselbe Kontextvektor ist, macht es nichts, wenn die Targets umsortiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([9.]), tensor([9.]), tensor([7.]), tensor([6.]), tensor([4.])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattened context vector\n",
    "context_vector = torch.randn(2)\n",
    "context_vectors_steps = torch.empty(5, int(max(length).item()), context_vector.size(0)) #so that all dims are specified as int\n",
    "for i in range(5):\n",
    "    for j in range(int(max(length).item())):\n",
    "        context_vectors_steps[i,j] = context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935],\n",
       "        [-1.5460,  0.7935]]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 3, 2, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed = torch.nn.utils.rnn.pack_padded_sequence(input=context_vectors_steps, lengths=length_s, batch_first=True)\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=2, hidden_size=20, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = lstm(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked, _= torch.nn.utils.rnn.pad_packed_sequence(packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935]],\n",
       "\n",
       "        [[-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935]],\n",
       "\n",
       "        [[-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [-1.5460,  0.7935],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (unpacked!= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_output = unpacked[mask]\n",
    "masked_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2 = (fixations != -1)\n",
    "masked_fixations = fixations[mask2]\n",
    "masked_fixations.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3 = (states != -1)\n",
    "masked_states = states[mask3]\n",
    "masked_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
