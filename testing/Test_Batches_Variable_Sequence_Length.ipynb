{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from utils.Dataset_And_Transforms import FigrimFillersDataset, Downsampling, ToTensor, SequenceModeling, ExpandTargets\n",
    "from utils.Create_Datasets import create_datasets   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_datasets(batch_size=5, data_transform=transforms.Compose([ToTensor(),Downsampling(10), SequenceModeling()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_l = []\n",
    "fixations_lengths = []\n",
    "for i, example in enumerate(train_loader): #start at index 0\n",
    "            # get the inputs\n",
    "            image = example[\"image\"]\n",
    "            fixations = example[\"fixations\"]\n",
    "            states = example[\"states\"]\n",
    "            length = example[\"fixations_length\"]\n",
    "\n",
    "            \n",
    "            if i == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 2])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixations.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the sequence lengths in descending order, keep track of the old indices, as the fixations' and token-indices'\n",
    "#batch-dimension needs to be rearranged in that way\n",
    "length_s, sort_idx = torch.sort(length, 0, descending=True)\n",
    "sort_idx\n",
    "#make length_s to list\n",
    "length_s = list(length_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange batch-dimensions (directly getting rid of the additional dimension this introduces)\n",
    "fixations = fixations[sort_idx].view(fixations.size(0), fixations.size(-2), fixations.size(-1))\n",
    "states = states[sort_idx].view(states.size(0), states.size(-1))\n",
    "#Da der Input immer derselbe Kontextvektor ist, macht es nichts, wenn die Targets umsortiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  1,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  2, -1, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([10.]), tensor([8.]), tensor([8.]), tensor([8.]), tensor([7.])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattened context vector\n",
    "context_vector = torch.randn(2)\n",
    "context_vectors_steps = torch.empty(5, int(max(length).item()), context_vector.size(0)) #so that all dims are specified as int\n",
    "for i in range(5):\n",
    "    for j in range(int(max(length).item())):\n",
    "        context_vectors_steps[i,j] = context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264],\n",
       "        [ 0.6166, -0.6856,  1.2264]]), batch_sizes=tensor([5, 5, 5, 5, 5, 3, 2]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#packed = torch.nn.utils.rnn.pack_padded_sequence(input=context_vectors_steps, lengths=length_s, batch_first=True)\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm = nn.LSTM(input_size=3, hidden_size=20, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "input_size = 2 #CNN context vector (eg 100x100, so flattened out 10000)\n",
    "hidden_size = 20 #vllt eher 10-50 Dimensionen\n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, gpu):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.rec_layer = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc_fix = nn.Linear(in_features=hidden_size, out_features=2) #x- and y-coordinate\n",
    "        self.fc_state = nn.Linear(in_features=hidden_size, out_features=3) #sos, eos, during sequence\n",
    "        self.gpu = gpu\n",
    "        if gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device(\"cuda\")\n",
    "                self.cuda()\n",
    "                \n",
    "    def forward(self, inputs, length):\n",
    "        packed_inputs = rnn_utils.pack_padded_sequence(input=inputs, lengths=length, batch_first=True)\n",
    "        output, (hidden, cell) = self.rec_layer(packed_inputs)\n",
    "        unpacked_output, _ = rnn_utils.pad_packed_sequence(output, batch_first=True, padding_value=-1)\n",
    "        out_fix = self.fc_fix(unpacked_output)\n",
    "        out_state = self.fc_state(unpacked_output)\n",
    "        return out_fix, out_state\n",
    "\n",
    "rnn_model = MyRNN(input_size=input_size, hidden_size=hidden_size, gpu=False) #lstm, gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, state = rnn_model(context_vectors_steps, length_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacked, _= torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([82])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([82])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixations = fixations[:,:output.size(1),:]\n",
    "mask = (fixations != -1)\n",
    "masked_output = output[mask]\n",
    "masked_fixations = fixations[mask]\n",
    "print(masked_fixations.size())\n",
    "masked_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_output = unpacked[mask]\n",
    "masked_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2 = (fixations != -1)\n",
    "masked_fixations = fixations[mask2]\n",
    "masked_fixations.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3 = (states != -1)\n",
    "masked_states = states[mask3]\n",
    "masked_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 10])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = state.permute(0,2,1)\n",
    "state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2000, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = states[:,:output.size(1)]\n",
    "loss = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "loss(state, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  1,  1,  1,  1,  1,  1,  2],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  2, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  2, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  1,  2, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1,  2, -1, -1, -1]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
